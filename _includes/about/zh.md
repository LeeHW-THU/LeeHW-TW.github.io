> 写写代码，做做设计，  
> 离开世界之前，一切都是过程。

#### 基本介绍：

李竑緯--

​	华南理工大学 软件工程

基本掌握：C++、Java、Python、Unity3D、Linux Shell。

框架：Pytorch、TensorFlow、Keras。

其他技能：组装电脑、笔记本维修、Android/IOS刷机、路由器部署/组网/管理。

#### 校内实习项目：

​	2018 年 3 月起 ：

##### 	**智慧医疗：**未来计算架构和视觉理解实验室 （ 华南理工大学，指导老师 副研究员 王小航 ）

​		**一 项目目标:**以医学仪器检测人体得到的2D图形，通过AI图像识别与NLP语音交互比对医疗数据库的信息判别症状和病情轻重，自动遥控机械臂使其对准确部位进行艾灸，或者提供给医生作为治疗的参考。

​		**二 项目说明**“**基于计算机视觉的自动定位穴位诊疗系统**”：

​		目标是通过患者输入的症状进行自然语言处理（NLP）进行文本分类，再根据摄像头捕捉的画面：

- 双目测距技术计算出相对距离
- 深度学习（DL）定位人体骨骼关键点
- 视觉处理（OpenCV）定位具体艾灸的穴位机械臂（单片机）根据三维坐标进行移动艾灸。



##### 	**深度强化学习中的迁移学习**：（ 华南理工大学，指导老师 副教授 陈百基 ）

​               深度强化学习（Deep Reinforcement Learning）是一种重要的机器学习方法， 在智能控制机器人及分析预测有着重要的应用。 2016 年谷歌公司开发的 AlphGo 战胜了人类的围棋冠军， 其主要用到的机器学习方法就是深度强化学习。 但是目前的深度强化学习需要大量样本的支持，这样的直接结果就是需要很长的训练时间才能达到很好的效果。 但在实际生活中，很多领域存在样本量过少丶数据采集困难丶样本时效性强的问题。研究者本项目提出将迁移学习（Transfer Learning）应用在深度强化学习上，着重于用已经训练好的模型去帮助训练新的模型，加速新模型的训练，并且提高模型的训练质量。

​				**在项目中的研究部分：**`<<Channel Pruning for Accelerating Very Deep Neural Networks>>` 

#### 竞赛项目：

​	**微软2017编程之美挑战赛（2017.3~2017.7）**

​	名次：全国复赛第九名

​	初赛阶段：初赛的内容是进行问答模型中的问题和答案的匹配。先使用word2vec进行词向量训练，训练后相加求平均得到句向量。然后利用余弦相似度匹配，达到0.54的准确率。

​	复赛阶段：为学校建立一个智能Bot。能进行学校官网信息的问答。由于机器学习模型匹配不精准，最后采用了关键词泛化匹配。

​	**汇丰金融科技创新黑客松大赛（2019.3~2019.6）**

​	名次：最具市场潜力奖

​	项目团队中的角色：项目经理、编程人员。管理团队进度，决定软件框架，实现数据存/取操作，根据公式绘制分析图表，设计与实现 GUI 界面视图。

​	作品：《金融投资评估系统》

​	简介：本项⽬技术以企业的年度财报相关信息为基础，通过整合相关信息和利用相关金融计算公式得到资产负债⽐率，五⼤大财务⽐率，⽤数据展现企业运营情况，最后分析股票⾛势，综合考虑来判断该企业是否值得投资。在以往的企业财报中，由于报表中的涉及的项目众多， 信息繁杂，往往需要我们花费⼤量的时间和精力提取相关的信息进行一一分析，在现有的金融分析展示中，结果往往仍然只是诸如“企业负债率”，“企业净利利率”等单独的项目，虽然比起直接⾯对报表已经直观很多，但还是不够清楚的展现各项之间的相关联系，因此我们在传统分析的基础上，对各项数据进行划分，分为“企业获利能力”，“企业偿债能力”，“企业经济效率”，“企业财务结构”四项分析，使各大银⾏或是投行可以更直观，更清楚地分析企业数据。

#### 实习经历：

​	**上海云从企业发展有限公司**

本次实习参与的项目是”基于深度学习在医疗切片中自动识别病灶位置”. 目标是透过数据训练，得出图像识别系统的训练结果文件，未来能在医疗切片中，自动准确识别出病灶种类，以及标出病灶的位置.

​           **我在项目中负责的部分:**

​	① 编写脚本文件, 根据病灶的Xml标注文件，对数百万的图片数据文件进行图形切割操作, 使用Opencv计算背景面积, 超出70%为白色（非病灶）的图片进行舍弃 ( 因为数据有数百万的图片文件, 所以我的 Python编程采取 Linux多线程，在服务器上运用多线程同时处理大量图片 ), 并且根据Xml标注文件给的ROI区域（病灶区） 与非ROI区域, 对图片数据文件名称及目录进行批量处理更改， 方能导入人工智能神经网络系统进行训练。

 	② 编写脚本文件根据需要的文件数目对数据进行随机批量移动, 以能进行先期的测试训练和调整。

​	③ 编写神经网络, 使用整理好的数据进行训练.使用的是Keras, 神经网络，架构是Resnet50 + GlobalAveragePooling2D + Dense + Dense, 得到 .h5的训练结果文件,并且对TensorBoard-log文件进行分析拟合情况.

​	④使用训练结果文件对测试数据进行预测,并且绘制预测结果图.

实习心得:

​	本次实习接触到百万数量级别的数据,操作了

​	（1）考虑运行效率与目标的情况下实现批处理数据.

​	（2）使用Keras编写神经网络

​	（3）了解并实际编写Resnet的网络结构 

​	（4）分析训练的拟合情况 

​	（5）最后测试训练结果绘制预测图。这些操作都在公司的 Linux + GPU（Titan Xp）x4的服务器上完成训练, 对这已经非常熟练。

本项目初步的预测结果与目标有段距离, 我主动仔细研究分析原因后，发现是因为医院给的数据, 并没有针对单一种类病灶的大量数据, 而是把各种病灶统一看作是异常而没有分类， 并且医院的标注质量只有方框，不是沿着病灶边缘准确标注，这样容易包含了一些正常的区域，所以我们和医院协商后，他们会提供新的一批高质量的数据.

在与医院讨论和等待提供新数据的过程中, 我研究了百度发表的论文`<<Cancer Metastasis Detection With Neural Conditional Random Field>>` 并以这个论文的数据和神经网络，编程训练复现了论文中的准确率, 发现此论文适用于检测癌症转移, 是使用NCRF(CNN+CRF) 条件随机场 + Resnet34的结构学习癌症的边缘特征，实现检测癌症转移的目标. 虽然论文中使用的数据与我们所做的项目有部分差异, 但是通过本篇论文，知道了数据应该如何标注才能达到在最好的预期效果，与训练模型的方法，这两者都对我日后所做的项目有帮助. 在这篇论文的基础上，我们项目小组重新定义最佳的标注法，并以此要求医院给我们更高质量的数据, 奠定了项目成功的基础。